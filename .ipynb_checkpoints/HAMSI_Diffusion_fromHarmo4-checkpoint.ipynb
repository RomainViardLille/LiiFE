{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97216c60-7edb-427b-9b34-4bd72b64d264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "#from data_load import load_data\n",
    "#from model import define_model\n",
    "#from harmonize import generate_harmonized_image\n",
    "#from model import define_diffusion\n",
    "#from training import train_model\n",
    "#from training_enhanced import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d15c9ba-4fa0-46a7-867b-3d9ab8c83b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NiftiiDataset(Dataset):\n",
    "    def __init__(self, source_paths, target_paths):\n",
    "        self.source_slices = []\n",
    "        self.target_slices = []\n",
    "\n",
    "        for source_path, target_path in zip(source_paths, target_paths):\n",
    "            source_nii = nib.load(source_path)\n",
    "            target_nii = nib.load(target_path)\n",
    "\n",
    "            source_img = torch.tensor(source_nii.get_fdata(dtype=np.float32))\n",
    "            target_img = torch.tensor(target_nii.get_fdata(dtype=np.float32))\n",
    "\n",
    "            source_slice = source_img[:, :, source_img.shape[2] // 2].unsqueeze(0)\n",
    "            target_slice = target_img[:, :, target_img.shape[2] // 2].unsqueeze(0)\n",
    "\n",
    "            self.source_slices.append(source_slice)\n",
    "            self.target_slices.append(target_slice)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source_slices[idx], self.target_slices[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7893a29-cb8c-4c11-9b13-bea9893393c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    source_image_paths = sorted(glob.glob(\"/home/youssef/harmo_4/ALL_training_data/Pat11*_CHU_zscore_minmax_unbias.nii.gz\"))\n",
    "    target_image_paths = sorted(glob.glob(\"/home/youssef/harmo_4/ALL_training_data/Pat11*_COL_zscore_minmax_unbias.nii.gz\"))\n",
    "\n",
    "    dataset = NiftiiDataset(source_image_paths, target_image_paths)\n",
    "    dataloader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbbd942c-4d4f-45bc-a328-5414b786fc05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Unet(\n",
    "        dim = 128,  # Increased dimensions\n",
    "        dim_mults = (1, 2, 4, 8),\n",
    "        channels = 1,  # Assuming grayscale MRI images\n",
    "        self_condition = True  # Enable self-conditioning\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5800349-8f44-400d-ba3a-041b7fae3eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_diffusion(model):\n",
    "    diffusion = GaussianDiffusion(\n",
    "        model = model,\n",
    "        image_size = 256,\n",
    "        timesteps = 1000,\n",
    "        objective = 'pred_noise',  # Change the objective if needed\n",
    "        beta_schedule = 'cosine',  # Changing noise schedule to cosine\n",
    "    )\n",
    "\n",
    "    return diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "584f6899-944f-4eb9-92c1-1ddefd93ee0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(dataloader, model, diffusion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Adjust step_size and gamma as needed\n",
    "\n",
    "    scaler = GradScaler()  # Initialize GradScaler\n",
    "\n",
    "    for epoch in range(20): \n",
    "        cpt=0\n",
    "        for source_slice, target_slice in dataloader:\n",
    "            source_slice, target_slice = source_slice.to(device), target_slice.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            timesteps = 1000\n",
    "            t = torch.randint(0, timesteps, (source_slice.size(0),), device=source_slice.device)\n",
    "\n",
    "            save_image(target_slice, 'target_'+str(epoch)+'_'+str(cpt)+'.png')\n",
    "            save_image(source_slice, 'source_'+str(epoch)+'_'+str(cpt)+'.png')\n",
    "            # Use autocast to run the forward pass in mixed precision\n",
    "            with autocast():\n",
    "                reconstructed_slice = model(source_slice, t)\n",
    "                loss = criterion(reconstructed_slice, target_slice)\n",
    "                save_image(reconstructed_slice,'reconstruct_'+str(epoch)+'_'+str(cpt)+'.png')\n",
    "\n",
    "            # Use GradScaler to scale the loss and call backward\n",
    "            scaler.scale(loss).backward()\n",
    "            # Use GradScaler to step the optimizer\n",
    "            scaler.step(optimizer)\n",
    "            # Update the scale for next iteration\n",
    "            scaler.update()\n",
    "            cpt=cpt+1\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "        scheduler.step()  # Update the learning rate\n",
    "        print(f\"Learning rate adjusted to: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "    torch.save(model.state_dict(), 'savedmodel_different_model_pat8.pt')\n",
    "    save_image(source_slice, 'harmonized_slice_88.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13bcf2aa-c61a-4361-91f7-e90f50e684d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_harmonized_image(model_path, source_image_path, target_image_path):\n",
    "    # Load the trained model\n",
    "    model = define_model()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # Load the source and target images\n",
    "    source_nii = nib.load(source_image_path)\n",
    "    target_nii = nib.load(target_image_path)\n",
    "\n",
    "    source_img = torch.tensor(source_nii.get_fdata(dtype=np.float32))\n",
    "    target_img = torch.tensor(target_nii.get_fdata(dtype=np.float32))\n",
    "\n",
    "    source_slice = source_img[:, :, source_img.shape[2] // 2].unsqueeze(0).unsqueeze(0)\n",
    "    target_slice = target_img[:, :, target_img.shape[2] // 2].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Generate a random timestep\n",
    "    timesteps = 1000\n",
    "    t = torch.randint(0, timesteps, (source_slice.size(0),), device=source_slice.device)\n",
    "\n",
    "    # Generate the harmonized image\n",
    "    with torch.no_grad():\n",
    "        harmonized_slice = model(source_slice, t)\n",
    "\n",
    "    # Save the harmonized image\n",
    "    save_image(harmonized_slice, '/home/youssef/harmo_4/harmonized_result/harmonized_slice8_dm_10ep.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f1c9a0b-c2cc-476a-b234-9205b53deab5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "Epoch 1, Loss: 0.1092502772808075\n",
      "Epoch 1, Loss: 0.13179025053977966\n",
      "Epoch 1, Loss: 1.4635510444641113\n",
      "Epoch 1, Loss: 1.4164683818817139\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 2, Loss: 1.4095628261566162\n",
      "Epoch 2, Loss: 0.14970599114894867\n",
      "Epoch 2, Loss: 0.0638352632522583\n",
      "Epoch 2, Loss: 0.0031716013327240944\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 3, Loss: 0.03259649872779846\n",
      "Epoch 3, Loss: 0.02056567184627056\n",
      "Epoch 3, Loss: 0.002363627078011632\n",
      "Epoch 3, Loss: 0.014938732609152794\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 4, Loss: 0.028853412717580795\n",
      "Epoch 4, Loss: 0.014280201867222786\n",
      "Epoch 4, Loss: 0.0026247708592563868\n",
      "Epoch 4, Loss: 0.013024034909904003\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 5, Loss: 0.016502177342772484\n",
      "Epoch 5, Loss: 0.006820809096097946\n",
      "Epoch 5, Loss: 0.0016480039339512587\n",
      "Epoch 5, Loss: 0.006739890668541193\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 6, Loss: 0.014854387380182743\n",
      "Epoch 6, Loss: 0.008057093247771263\n",
      "Epoch 6, Loss: 0.0015543561894446611\n",
      "Epoch 6, Loss: 0.004432189278304577\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 7, Loss: 0.0066651166416704655\n",
      "Epoch 7, Loss: 0.005205817520618439\n",
      "Epoch 7, Loss: 0.002854771912097931\n",
      "Epoch 7, Loss: 0.0021314413752406836\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 8, Loss: 0.004843324422836304\n",
      "Epoch 8, Loss: 0.005054012406617403\n",
      "Epoch 8, Loss: 0.0020074360072612762\n",
      "Epoch 8, Loss: 0.001422049244865775\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 9, Loss: 0.003244974883273244\n",
      "Epoch 9, Loss: 0.004049757961183786\n",
      "Epoch 9, Loss: 0.00448074284940958\n",
      "Epoch 9, Loss: 0.001430915086530149\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 10, Loss: 0.0032355778384953737\n",
      "Epoch 10, Loss: 0.004481637850403786\n",
      "Epoch 10, Loss: 0.001582936616614461\n",
      "Epoch 10, Loss: 0.001347384531982243\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 11, Loss: 0.0016672558849677444\n",
      "Epoch 11, Loss: 0.001376536674797535\n",
      "Epoch 11, Loss: 0.0021530562080442905\n",
      "Epoch 11, Loss: 0.00133765977807343\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 12, Loss: 0.0017032567411661148\n",
      "Epoch 12, Loss: 0.0014737300807610154\n",
      "Epoch 12, Loss: 0.0017181681469082832\n",
      "Epoch 12, Loss: 0.0012582966592162848\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 13, Loss: 0.0016882731579244137\n",
      "Epoch 13, Loss: 0.0013579848455265164\n",
      "Epoch 13, Loss: 0.0014266720972955227\n",
      "Epoch 13, Loss: 0.0013447075616568327\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 14, Loss: 0.002103258855640888\n",
      "Epoch 14, Loss: 0.0017455077031627297\n",
      "Epoch 14, Loss: 0.0015242050867527723\n",
      "Epoch 14, Loss: 0.001563833560794592\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 15, Loss: 0.00198360881768167\n",
      "Epoch 15, Loss: 0.0012545300414785743\n",
      "Epoch 15, Loss: 0.0017028534784913063\n",
      "Epoch 15, Loss: 0.0012052233796566725\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 16, Loss: 0.0018776002107188106\n",
      "Epoch 16, Loss: 0.0014305197400972247\n",
      "Epoch 16, Loss: 0.0012444856110960245\n",
      "Epoch 16, Loss: 0.0012402281863614917\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 17, Loss: 0.0019890295807272196\n",
      "Epoch 17, Loss: 0.0018396651139482856\n",
      "Epoch 17, Loss: 0.0013597551733255386\n",
      "Epoch 17, Loss: 0.001547432504594326\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 18, Loss: 0.00162053934764117\n",
      "Epoch 18, Loss: 0.001483401283621788\n",
      "Epoch 18, Loss: 0.0016817118739709258\n",
      "Epoch 18, Loss: 0.0017680099699646235\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 19, Loss: 0.001897609094157815\n",
      "Epoch 19, Loss: 0.0013950411230325699\n",
      "Epoch 19, Loss: 0.001203174702823162\n",
      "Epoch 19, Loss: 0.0012022883165627718\n",
      "Learning rate adjusted to: 1e-05\n",
      "Epoch 20, Loss: 0.0016833312110975385\n",
      "Epoch 20, Loss: 0.0018447221955284476\n",
      "Epoch 20, Loss: 0.0012085831258445978\n",
      "Epoch 20, Loss: 0.001279350370168686\n",
      "Learning rate adjusted to: 1.0000000000000002e-06\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dataloader = load_data()\n",
    "    #model = define_model().to(device)\n",
    "    model = define_model()\n",
    "    diffusion = define_diffusion(model)\n",
    "    train_model(dataloader, model, diffusion)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02181add-b90e-4620-91a5-d976e024a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_image_path = \"/home/youssef/harmo_4/test_data/Pat42_CHU_zscore_minmax_unbias.nii.gz\"\n",
    "#target_image_path = \"/home/youssef/harmo_4/test_data/Pat42_COL_zscore_minmax_unbias.nii.gz\"\n",
    "source_image_path = \"/home/youssef/harmo_4/training_data/Pat8_CHU_zscore_minmax_unbias.nii.gz\"\n",
    "target_image_path = \"/home/youssef/harmo_4/training_data/Pat8_COL_zscore_minmax_unbias.nii.gz\"\n",
    "model_path = \"/home/youssef/harmo_4/trained_model/savedmodel_different_model_pat8.pt\"\n",
    "\n",
    "generate_harmonized_image(model_path, source_image_path, target_image_path)\n",
    "#generate_harmonized_image('savedmodel.pt', source_image_path, target_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
